{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code from: https://keras.io/examples/nlp/lstm_seq2seq/\n",
    "Author: @fchollet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = \"data/rus.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  10000\n",
      "Number of unique input tokens: 73\n",
      "Number of unique output tokens: 85\n",
      "Max sequence length for inputs: 14\n",
      "Max sequence length for outputs: 60\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split(\"\\t\")\n",
    "    # we use \"tab\" as the start sequence character\n",
    "    # for the targets, and \"\\n\" as the end sequence character.\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "            \n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print(\"Number of samples: \", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines an input sequence and processes it\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# we discard encoder_outputs and keep only the states\n",
    "encoder_states = state_h, state_c\n",
    "\n",
    "# set up the decoder using encoder_states as the initial state\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# encoder_input_data & decoder_input_data into target_data\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 19s 128ms/step - loss: 1.3112 - accuracy: 0.7472 - val_loss: 0.8474 - val_accuracy: 0.7679\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.7309 - accuracy: 0.8090 - val_loss: 0.8328 - val_accuracy: 0.7920\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 0.6145 - accuracy: 0.8355 - val_loss: 0.6830 - val_accuracy: 0.8315\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 17s 133ms/step - loss: 0.5372 - accuracy: 0.8521 - val_loss: 0.5607 - val_accuracy: 0.8386\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 14s 116ms/step - loss: 0.4843 - accuracy: 0.8600 - val_loss: 0.5203 - val_accuracy: 0.8502\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 15s 118ms/step - loss: 0.4557 - accuracy: 0.8676 - val_loss: 0.4969 - val_accuracy: 0.8574\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.4336 - accuracy: 0.8732 - val_loss: 0.4902 - val_accuracy: 0.8580\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 15s 118ms/step - loss: 0.4078 - accuracy: 0.8805 - val_loss: 0.4687 - val_accuracy: 0.8637\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.3909 - accuracy: 0.8854 - val_loss: 0.4557 - val_accuracy: 0.8680\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 21s 165ms/step - loss: 0.3743 - accuracy: 0.8900 - val_loss: 0.4428 - val_accuracy: 0.8709\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.3560 - accuracy: 0.8954 - val_loss: 0.4344 - val_accuracy: 0.8743\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 0.3429 - accuracy: 0.8997 - val_loss: 0.4277 - val_accuracy: 0.8764\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 15s 123ms/step - loss: 0.3286 - accuracy: 0.9038 - val_loss: 0.4215 - val_accuracy: 0.8781\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 15s 118ms/step - loss: 0.3151 - accuracy: 0.9077 - val_loss: 0.4194 - val_accuracy: 0.8795\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 15s 120ms/step - loss: 0.3042 - accuracy: 0.9112 - val_loss: 0.4147 - val_accuracy: 0.8808\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 15s 117ms/step - loss: 0.2884 - accuracy: 0.9154 - val_loss: 0.4119 - val_accuracy: 0.8819\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.2796 - accuracy: 0.9178 - val_loss: 0.4082 - val_accuracy: 0.8832\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 15s 117ms/step - loss: 0.2675 - accuracy: 0.9219 - val_loss: 0.4050 - val_accuracy: 0.8856\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.2578 - accuracy: 0.9238 - val_loss: 0.4108 - val_accuracy: 0.8840\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.2458 - accuracy: 0.9275 - val_loss: 0.4070 - val_accuracy: 0.8849\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.2379 - accuracy: 0.9295 - val_loss: 0.4081 - val_accuracy: 0.8854\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.2278 - accuracy: 0.9329 - val_loss: 0.4052 - val_accuracy: 0.8859\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.2174 - accuracy: 0.9358 - val_loss: 0.4051 - val_accuracy: 0.8879\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.2107 - accuracy: 0.9375 - val_loss: 0.4110 - val_accuracy: 0.8875\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 15s 117ms/step - loss: 0.2029 - accuracy: 0.9397 - val_loss: 0.4112 - val_accuracy: 0.8877\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 15s 121ms/step - loss: 0.1951 - accuracy: 0.9421 - val_loss: 0.4102 - val_accuracy: 0.8885\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.1882 - accuracy: 0.9444 - val_loss: 0.4158 - val_accuracy: 0.8885\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.1810 - accuracy: 0.9458 - val_loss: 0.4147 - val_accuracy: 0.8897\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.1751 - accuracy: 0.9479 - val_loss: 0.4205 - val_accuracy: 0.8893\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.1695 - accuracy: 0.9493 - val_loss: 0.4245 - val_accuracy: 0.8891\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.1641 - accuracy: 0.9507 - val_loss: 0.4240 - val_accuracy: 0.8895\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.1587 - accuracy: 0.9523 - val_loss: 0.4329 - val_accuracy: 0.8890\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.1519 - accuracy: 0.9546 - val_loss: 0.4328 - val_accuracy: 0.8893\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.1464 - accuracy: 0.9559 - val_loss: 0.4424 - val_accuracy: 0.8885\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.1433 - accuracy: 0.9565 - val_loss: 0.4440 - val_accuracy: 0.8889\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.1373 - accuracy: 0.9585 - val_loss: 0.4525 - val_accuracy: 0.8885\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 15s 117ms/step - loss: 0.1331 - accuracy: 0.9594 - val_loss: 0.4479 - val_accuracy: 0.8899\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.1277 - accuracy: 0.9613 - val_loss: 0.4610 - val_accuracy: 0.8880\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.1234 - accuracy: 0.9623 - val_loss: 0.4648 - val_accuracy: 0.8879\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.1199 - accuracy: 0.9635 - val_loss: 0.4667 - val_accuracy: 0.8881\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 15s 119ms/step - loss: 0.1148 - accuracy: 0.9649 - val_loss: 0.4683 - val_accuracy: 0.8888\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 14s 116ms/step - loss: 0.1121 - accuracy: 0.9658 - val_loss: 0.4780 - val_accuracy: 0.8875\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.1085 - accuracy: 0.9668 - val_loss: 0.4791 - val_accuracy: 0.8887\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 14s 116ms/step - loss: 0.1047 - accuracy: 0.9679 - val_loss: 0.4826 - val_accuracy: 0.8887\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 14s 116ms/step - loss: 0.1030 - accuracy: 0.9683 - val_loss: 0.4902 - val_accuracy: 0.8876\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0999 - accuracy: 0.9694 - val_loss: 0.4986 - val_accuracy: 0.8886\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0957 - accuracy: 0.9705 - val_loss: 0.4996 - val_accuracy: 0.8880\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0933 - accuracy: 0.9710 - val_loss: 0.5046 - val_accuracy: 0.8883\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0899 - accuracy: 0.9717 - val_loss: 0.5143 - val_accuracy: 0.8873\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.0866 - accuracy: 0.9732 - val_loss: 0.5147 - val_accuracy: 0.8876\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 15s 117ms/step - loss: 0.0846 - accuracy: 0.9737 - val_loss: 0.5191 - val_accuracy: 0.8872\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 15s 117ms/step - loss: 0.0835 - accuracy: 0.9742 - val_loss: 0.5297 - val_accuracy: 0.8867\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 15s 118ms/step - loss: 0.0803 - accuracy: 0.9751 - val_loss: 0.5296 - val_accuracy: 0.8878\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 15s 116ms/step - loss: 0.0783 - accuracy: 0.9750 - val_loss: 0.5404 - val_accuracy: 0.8874\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 15s 118ms/step - loss: 0.0760 - accuracy: 0.9758 - val_loss: 0.5395 - val_accuracy: 0.8877\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 14s 116ms/step - loss: 0.0736 - accuracy: 0.9765 - val_loss: 0.5393 - val_accuracy: 0.8870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "125/125 [==============================] - 14s 116ms/step - loss: 0.0699 - accuracy: 0.9780 - val_loss: 0.5490 - val_accuracy: 0.8883\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0709 - accuracy: 0.9775 - val_loss: 0.5507 - val_accuracy: 0.8879\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0688 - accuracy: 0.9778 - val_loss: 0.5591 - val_accuracy: 0.8877\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0664 - accuracy: 0.9788 - val_loss: 0.5651 - val_accuracy: 0.8873\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0652 - accuracy: 0.9791 - val_loss: 0.5642 - val_accuracy: 0.8882\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0625 - accuracy: 0.9800 - val_loss: 0.5709 - val_accuracy: 0.8877\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0613 - accuracy: 0.9804 - val_loss: 0.5735 - val_accuracy: 0.8872\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 14s 112ms/step - loss: 0.0594 - accuracy: 0.9805 - val_loss: 0.5722 - val_accuracy: 0.8879\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 14s 112ms/step - loss: 0.0580 - accuracy: 0.9810 - val_loss: 0.5764 - val_accuracy: 0.8884\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0569 - accuracy: 0.9811 - val_loss: 0.5836 - val_accuracy: 0.8878\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0560 - accuracy: 0.9816 - val_loss: 0.5864 - val_accuracy: 0.8878\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0545 - accuracy: 0.9820 - val_loss: 0.5937 - val_accuracy: 0.8872\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0528 - accuracy: 0.9825 - val_loss: 0.5935 - val_accuracy: 0.8883\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0520 - accuracy: 0.9827 - val_loss: 0.6052 - val_accuracy: 0.8872\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0513 - accuracy: 0.9827 - val_loss: 0.6012 - val_accuracy: 0.8877\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0502 - accuracy: 0.9832 - val_loss: 0.6046 - val_accuracy: 0.8881\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0494 - accuracy: 0.9830 - val_loss: 0.6101 - val_accuracy: 0.8878\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0487 - accuracy: 0.9834 - val_loss: 0.6151 - val_accuracy: 0.8873\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0475 - accuracy: 0.9838 - val_loss: 0.6197 - val_accuracy: 0.8883\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 14s 112ms/step - loss: 0.0466 - accuracy: 0.9842 - val_loss: 0.6233 - val_accuracy: 0.8873\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0459 - accuracy: 0.9841 - val_loss: 0.6265 - val_accuracy: 0.8874\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0451 - accuracy: 0.9842 - val_loss: 0.6309 - val_accuracy: 0.8875\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0447 - accuracy: 0.9847 - val_loss: 0.6284 - val_accuracy: 0.8871\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0441 - accuracy: 0.9846 - val_loss: 0.6347 - val_accuracy: 0.8868\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0430 - accuracy: 0.9852 - val_loss: 0.6349 - val_accuracy: 0.8875\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0425 - accuracy: 0.9848 - val_loss: 0.6404 - val_accuracy: 0.8863\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0417 - accuracy: 0.9852 - val_loss: 0.6447 - val_accuracy: 0.8864\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.0409 - accuracy: 0.9856 - val_loss: 0.6445 - val_accuracy: 0.8874\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0402 - accuracy: 0.9855 - val_loss: 0.6498 - val_accuracy: 0.8872\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0400 - accuracy: 0.9857 - val_loss: 0.6462 - val_accuracy: 0.8875\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.0390 - accuracy: 0.9858 - val_loss: 0.6472 - val_accuracy: 0.8876\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.0377 - accuracy: 0.9861 - val_loss: 0.6561 - val_accuracy: 0.8868\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0383 - accuracy: 0.9861 - val_loss: 0.6548 - val_accuracy: 0.8870\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0378 - accuracy: 0.9862 - val_loss: 0.6527 - val_accuracy: 0.8880\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0378 - accuracy: 0.9861 - val_loss: 0.6633 - val_accuracy: 0.8864\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.0374 - accuracy: 0.9862 - val_loss: 0.6606 - val_accuracy: 0.8871\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0369 - accuracy: 0.9863 - val_loss: 0.6616 - val_accuracy: 0.8877\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 14s 112ms/step - loss: 0.0360 - accuracy: 0.9866 - val_loss: 0.6685 - val_accuracy: 0.8874\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0360 - accuracy: 0.9867 - val_loss: 0.6617 - val_accuracy: 0.8874\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0359 - accuracy: 0.9867 - val_loss: 0.6667 - val_accuracy: 0.8874\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.0356 - accuracy: 0.9866 - val_loss: 0.6712 - val_accuracy: 0.8866\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 15s 116ms/step - loss: 0.0352 - accuracy: 0.9867 - val_loss: 0.6761 - val_accuracy: 0.8869\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.0352 - accuracy: 0.9868 - val_loss: 0.6764 - val_accuracy: 0.8872\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.0344 - accuracy: 0.9868 - val_loss: 0.6760 - val_accuracy: 0.8867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s\\assets\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "# Save model\n",
    "model.save(\"s2s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference (sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "# Restore the model and construct the encoder and decoder\n",
    "model = keras.models.load_model(\"s2s\")\n",
    "\n",
    "encoder_inputs = model.input[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
